{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3193d4b-0fcb-4efd-ac0d-573117eb21be",
   "metadata": {},
   "source": [
    "# Prerequisites \n",
    "\n",
    "To run this pipeline, you need the `ogc-na` Python module to be installed in your environment (for example, by running `pip install ogc-na`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e17ef49-98ad-4f3a-a989-7401fe233dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ogc.na import download, ingest_json, update_vocabs\n",
    "from ogc.na.domain_config import DomainConfiguration\n",
    "import json\n",
    "from rdflib import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dee44d-44d9-4cad-82dd-368ab5ffb787",
   "metadata": {},
   "source": [
    "# Running the pipeline\n",
    "\n",
    "This section shows a step-by-step usage of the OGC Rainbow data download + semantic uplift + entailment + validation pipeline.\n",
    "\n",
    "We will run all the steps in the current directory.\n",
    "\n",
    "## Download Google Spreadsheet as CSV\n",
    "\n",
    "Google Spreadsheets can be downloaded by using a specially-crafted URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73804259-802e-4cd7-b6a0-1c6d31442488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://docs.google.com/spreadsheets/d/1zOGLWpTr784nTzBO-S_Es_WUyRsK7650/export?format=csv\n"
     ]
    }
   ],
   "source": [
    "GS_ID = '1zOGLWpTr784nTzBO-S_Es_WUyRsK7650'\n",
    "GS_URL = f\"https://docs.google.com/spreadsheets/d/{GS_ID}/export?format=csv\"\n",
    "CSV_DEST = 'iso19156-3-examples.csv'\n",
    "download.download_file(GS_URL, CSV_DEST, object_diff=False)\n",
    "print(\"Downloaded\", GS_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba2d1e-0d42-4a41-bc21-e2e6df35ae9b",
   "metadata": {},
   "source": [
    "The `object_diff` key is used when working with JSON files, so in this case we need to disable it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb318df8-e863-4a89-9c85-69585c8e991c",
   "metadata": {},
   "source": [
    "## Convert CSV to JSON\n",
    "\n",
    "Once we have our `iso19156-3-examples.csv` file, we need to convert it to JSON.\n",
    "\n",
    "`ingest_json`, the module [used to perform semantic uplifts](https://opengeospatial.github.io/ogc-na-tools/reference/ogc/na/ingest_json/) (turning plain JSON into JSON-LD and/or RDF/Turtle), has an [input filter that can work with CSV files](https://opengeospatial.github.io/ogc-na-tools/reference/ogc/na/input_filters/csv/). Normally, we would create a whole semantic uplift definition (following the steps in [this tutorial](https://opengeospatial.github.io/ogc-na-tools/tutorials/#how-to-create-a-json-ld-uplift-context-definition)), but in this case we just want a JSON version of our spreadsheet, so we can use an extremely simple uplift definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecaead9f-b179-4448-80aa-2cf71713e085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_to_json.yml created\n"
     ]
    }
   ],
   "source": [
    "csv_to_json_def = '''\n",
    "input-filter:\n",
    "  csv:\n",
    "'''\n",
    "with open('csv_to_json.yml', 'w') as f:\n",
    "    f.write(csv_to_json_def)\n",
    "print('csv_to_json.yml created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a9938-a61f-4df4-a6e9-30e20e249dd8",
   "metadata": {},
   "source": [
    "Then we can run the `ingest_json` module with [that definition](csv_to_json.yml) to obtain our JSON document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e49c7f-94a3-4053-8e00-1bd7bfb5c359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso19156-3-examples.csv.json created\n"
     ]
    }
   ],
   "source": [
    "result = ingest_json.process_file(input_fn='iso19156-3-examples.csv',\n",
    "                                  jsonld_fn='iso19156-3-examples.csv.json',\n",
    "                                  context_fn='csv_to_json.yml')\n",
    "print('iso19156-3-examples.csv.json created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a356f40-9fd8-4407-8db3-3485805073f9",
   "metadata": {},
   "source": [
    "As you can see, the newly-created [iso19156-3-examples.csv.json](iso19156-3-examples.csv.json) document contains an object with two keys:\n",
    "\n",
    "* `metadata`, which contains metadata about the input file, the filter that was used, etc.\n",
    "* `data`, with an array of objects representing the rows in the spreadsheet.\n",
    "\n",
    "## Semantic uplift\n",
    "\n",
    "Once our data is in JSON format, we can perform a semantic uplift on it, which is basically converting plain old JSON into JSON-LD and/or RDF in Turtle format.\n",
    "\n",
    "For this step, we will use [an already existing uplift definition](https://raw.githubusercontent.com/avillar/iso19157-3-sample/master/properties-uplift.yml):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426b1526-9d83-452a-b4ca-d7d8c296a96a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "properties-uplift.yml created\n"
     ]
    }
   ],
   "source": [
    "download.download_file('https://raw.githubusercontent.com/avillar/iso19157-3-sample/master/properties-uplift.yml',\n",
    "                       'properties-uplift.yml',\n",
    "                       object_diff=False)\n",
    "print('properties-uplift.yml downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df3e71-79ef-41d3-a321-2fad6eb6512b",
   "metadata": {},
   "source": [
    "Let us review what [this uplift definition](properties-uplift.yml) does:\n",
    "\n",
    "1. It contains 4 `transform`s ([jq](https://stedolan.github.io/jq/) expressions to manipulate the input document):\n",
    "    1. We take the value of the `data` key and discard the rest.\n",
    "    2. We walk through the data tree and remove (set to `null`) all values that empty strings, strings made up of blank space characters only, or strings that are just a dash (`-`).\n",
    "    3. Since some headers contained colons, we remove all colons inside property keys in the object.\n",
    "    4. We add a `skos:ConceptScheme` with some metadata as the top-level object, and put all of the row objects inside its `concepts` property.\n",
    "2. After the `transform`s run, we add the `skos:Concept` type for all of the rows (remember that they are now inside the `concepts` property of the top-level object).\n",
    "3. Finally, we add the JSON-LD context at the root level of the document (indicated by using the `$` JSON path).\n",
    "\n",
    "We run it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cc6af7-0f99-495a-a691-948e10afa9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = ingest_json.process_file(input_fn='iso19156-3-examples.csv.json',\n",
    "                                  jsonld_fn='iso19156-3-examples.csv.jsonld',\n",
    "                                  ttl_fn='iso19156-3-examples.csv.ttl',\n",
    "                                  context_fn='properties-uplift.yml')\n",
    "print('Semantic uplift done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9c997-10d7-4d90-9d54-6c8ee346168e",
   "metadata": {},
   "source": [
    "The above command will generate two files:\n",
    "\n",
    "* [iso19156-3-examples.csv.jsonld](iso19156-3-examples.csv.jsonld), which is the uplifted JSON-LD version after running the `transform`s, setting the `types` and adding the `context`.\n",
    "* [iso19156-3-examples.csv.ttl](iso19156-3-examples.csv.ttl), its equivalent version in Turtle.\n",
    "\n",
    "You will note that the Turtle version does not have all of the properties that the JSON-LD document does; this is because, from the RDF side of things, any property that is not linked to an RDF predicate is simply ignored.\n",
    "\n",
    "## Entailment and validation\n",
    "\n",
    "At this point, we have an RDF graph version of our initial spreadsheet inside the [iso19156-3-examples.csv.ttl](iso19156-3-examples.csv.ttl) file. The next step involves performing entailment (inferring new data that we can add to our graph) and validation (verifying that our data is \"up to code\"). We can do this by leveraging a couple of technologies:\n",
    "\n",
    "* [SHACL](https://www.w3.org/TR/shacl/) allows us to write entailment rules and validation constraints for RDF data.\n",
    "* [The profiles vocabulary](https://www.w3.org/TR/dx-prof/) can be used to create profiles, and link those with entailment and validation resources.\n",
    "  * The OGC defines several profiles that can be used for validation and entailment of RDF resources.\n",
    "\n",
    "To associate our own Turtle files with the profiles, we first need to create a [DomainConfiguration](https://opengeospatial.github.io/ogc-na-tools/reference/ogc/na/domain_config/#ogc.na.domain_config.DomainConfiguration) (you can find a full example with comments [here](https://opengeospatial.github.io/ogc-na-tools/examples/#sample-domain-configuration)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c91cd9e9-82f6-49ae-a41f-8be5d12914bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found profiles:\n",
      "http://www.opengis.net/def/metamodel/profiles/dcatprov\n",
      "http://www.opengis.net/def/metamodel/profiles/dcatqb\n",
      "http://www.opengis.net/def/metamodel/profiles/json_ld_context\n",
      "http://www.opengis.net/def/metamodel/profiles/ogcapi-bbox\n",
      "http://www.opengis.net/def/metamodel/profiles/ogcapi-common\n",
      "http://www.opengis.net/def/metamodel/profiles/ogcapi-edr\n",
      "http://www.opengis.net/def/metamodel/profiles/ogcapi-features\n",
      "http://www.opengis.net/def/metamodel/profiles/ogcapi-geopose\n",
      "http://www.opengis.net/def/metamodel/profiles/ogcapi-geopose-euler\n",
      "http://www.opengis.net/def/metamodel/profiles/owl2skos\n",
      "http://www.opengis.net/def/metamodel/profiles/skos_conceptscheme\n",
      "http://www.opengis.net/def/metamodel/profiles/skos_conceptscheme_ogc\n",
      "http://www.opengis.net/def/metamodel/profiles/skos_shared\n",
      "http://www.opengis.net/def/metamodel/profiles/vocprez_ogc\n",
      "http://www.w3.org/2004/02/skos/core\n",
      "http://www.w3.org/ns/dcat\n"
     ]
    }
   ],
   "source": [
    "domain_cfg_content = '''\n",
    "@prefix dcfg: <http://www.example.org/ogc/domain-cfg#> .\n",
    "@prefix dcat: <http://www.w3.org/ns/dcat#> .\n",
    "@prefix dct: <http://purl.org/dc/terms/> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix profiles: <http://www.opengis.net/def/metamodel/profiles/> .\n",
    "\n",
    "_:iso19157-3-sample a dcat:Catalog ;\n",
    "  dct:title \"ISO19157-3 Sample\" ;\n",
    "  dcat:dataset _:examples ;\n",
    "  dcfg:hasProfileSource \"sparql:http://defs-dev.opengis.net:8080/rdf4j-server/repositories/profiles\" ;\n",
    "  dcfg:ignoreProfileArtifactErrors true ;\n",
    ".\n",
    "\n",
    "_:examples a dcat:Dataset, dcfg:DomainConfiguration ;\n",
    "  dct:identifier \"examples\" ;\n",
    "  dct:description \"Entailment and validation for examples\" ;\n",
    "  dcfg:glob \"*.ttl\" ;\n",
    "  dct:conformsTo profiles:skos_shared, profiles:skos_conceptscheme, profiles:skos_conceptscheme_ogc, profiles:vocprez_ogc ;\n",
    ".\n",
    "'''\n",
    "domain_cfg = DomainConfiguration(Graph().parse(data=domain_cfg_content))\n",
    "profile_registry = domain_cfg.profile_registry\n",
    "print('Found profiles:')\n",
    "print('\\n'.join(str(profile_uri) for profile_uri in sorted(profile_registry.profiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeecdb9-bcd8-480f-bc74-c642d8214015",
   "metadata": {},
   "source": [
    "The `profile_registry` above is a [ProfileRegistry](https://opengeospatial.github.io/ogc-na-tools/reference/ogc/na/profile/#ogc.na.profile.ProfileRegistry), which reads the values for the catalog's `dcfg:hasProfileSource` (`sparql:http://defs-dev.opengis.net:8080/rdf4j-server/repositories/profiles`, a SPARQL endpoint, in our case), and obtains all the profile definitions, including its resources, artifacts and dependencies, from them.\n",
    "\n",
    "Apart from that, we define a `dcfg:DomainConfiguration` to run entailment and validation processes on our Turtle document (which will fall inside of the `dcfg:glob`'s scope) with resources from 4 profiles: `skos_shared`, `skos_conceptscheme`, `skos_conceptscheme_ogc` and `vocprez_ogc`.\n",
    "\n",
    "Since the previous uplift `result` has a `graph` property with the RDF, we can run entailments directly on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7bbb3ed-e844-44eb-b81a-6c44fdef13c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rdflib.term.URIRef('http://www.opengis.net/def/metamodel/profiles/skos_shared'), rdflib.term.URIRef('http://www.opengis.net/def/metamodel/profiles/vocprez_ogc'), rdflib.term.URIRef('http://www.opengis.net/def/metamodel/profiles/skos_conceptscheme_ogc'), rdflib.term.URIRef('http://www.opengis.net/def/metamodel/profiles/skos_conceptscheme')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m cfg_entry \u001b[38;5;241m=\u001b[39m domain_cfg\u001b[38;5;241m.\u001b[39mentries\u001b[38;5;241m.\u001b[39mfind_entry_for_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso19156-3-examples.csv.ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cfg_entry\u001b[38;5;241m.\u001b[39mconforms_to)\n\u001b[0;32m----> 3\u001b[0m entailed_graph, entail_artifacts \u001b[38;5;241m=\u001b[39m \u001b[43mprofile_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_entry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconforms_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m entailed_graph\u001b[38;5;241m.\u001b[39mserialize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso19156-3-examples.csv-entailed.ttl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntailement done. Artifacts used:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/ogc/na/profile.py:319\u001b[0m, in \u001b[0;36mProfileRegistry.entail\u001b[0;34m(self, g, additional_profiles, inplace, recursive)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_artifacts:\n\u001b[1;32m    318\u001b[0m     artifacts\u001b[38;5;241m.\u001b[39mupdate(extra_artifacts)\n\u001b[0;32m--> 319\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m profile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiles\u001b[38;5;241m.\u001b[39mget(profile_ref)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recursive \u001b[38;5;129;01mand\u001b[39;00m profile \u001b[38;5;129;01mand\u001b[39;00m profile\u001b[38;5;241m.\u001b[39mprofile_of:\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/ogc/na/util.py:86\u001b[0m, in \u001b[0;36mentail\u001b[0;34m(g, rules, extra, inplace)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m     85\u001b[0m     g \u001b[38;5;241m=\u001b[39m copy_triples(g)\n\u001b[0;32m---> 86\u001b[0m \u001b[43mshacl_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshacl_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mont_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madvanced\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entailed_extra:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m triple \u001b[38;5;129;01min\u001b[39;00m entailed_extra:\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/pyshacl/validate.py:455\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(data_graph, shacl_graph, ont_graph, advanced, inference, inplace, abort_on_first, allow_infos, allow_warnings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     validator \u001b[38;5;241m=\u001b[39m \u001b[43mValidator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_dg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshacl_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloaded_sg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mont_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloaded_og\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_debug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minference\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabort_on_first\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mabort_on_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallow_infos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallow_warnings\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_warnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madvanced\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43madvanced\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_rules\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miterate_rules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_js\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_js\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogger\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     conforms, report_graph, report_text \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationFailure \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/pyshacl/validate.py:195\u001b[0m, in \u001b[0;36mValidator.__init__\u001b[0;34m(self, data_graph, shacl_graph, ont_graph, options, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mont_graph\u001b[38;5;241m.\u001b[39mdefault_union \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shacl_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     shacl_graph \u001b[38;5;241m=\u001b[39m \u001b[43mclone_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshacl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shacl_graph, rdflib\u001b[38;5;241m.\u001b[39mGraph), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshacl_graph must be a rdflib Graph object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshacl_graph \u001b[38;5;241m=\u001b[39m ShapesGraph(shacl_graph, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger)  \u001b[38;5;66;03m# type: ShapesGraph\u001b[39;00m\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/pyshacl/rdfutil/clone.py:58\u001b[0m, in \u001b[0;36mclone_graph\u001b[0;34m(source_graph, target_graph, identifier)\u001b[0m\n\u001b[1;32m     56\u001b[0m     g \u001b[38;5;241m=\u001b[39m rdflib\u001b[38;5;241m.\u001b[39mGraph(identifier\u001b[38;5;241m=\u001b[39midentifier)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, n \u001b[38;5;129;01min\u001b[39;00m source_graph\u001b[38;5;241m.\u001b[39mnamespace_manager\u001b[38;5;241m.\u001b[39mnamespaces():\n\u001b[0;32m---> 58\u001b[0m         \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamespace_manager\u001b[49m\u001b[38;5;241m.\u001b[39mbind(p, n, override\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     g \u001b[38;5;241m=\u001b[39m target_graph\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/rdflib/graph.py:474\u001b[0m, in \u001b[0;36mGraph.namespace_manager\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03mthis graph's namespace-manager\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__namespace_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__namespace_manager \u001b[38;5;241m=\u001b[39m \u001b[43mNamespaceManager\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind_namespaces\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__namespace_manager\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/rdflib/namespace/__init__.py:425\u001b[0m, in \u001b[0;36mNamespaceManager.__init__\u001b[0;34m(self, graph, bind_namespaces)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m bind_namespaces \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrdflib\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# bind all the Namespaces shipped with RDFLib\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prefix, ns \u001b[38;5;129;01min\u001b[39;00m _NAMESPACE_PREFIXES_RDFLIB\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 425\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# ... don't forget the core ones too\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prefix, ns \u001b[38;5;129;01min\u001b[39;00m _NAMESPACE_PREFIXES_CORE\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/rdflib/namespace/__init__.py:664\u001b[0m, in \u001b[0;36mNamespaceManager.bind\u001b[0;34m(self, prefix, namespace, override, replace)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    650\u001b[0m     prefix: Optional[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     replace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    655\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Bind a given namespace to the prefix\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m    If override, rebind, even if the given namespace is already\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m \n\u001b[1;32m    662\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m URIRef(\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;66;03m# When documenting explain that override only applies in what cases\u001b[39;00m\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/work/Proyectos/ogc/jupyter/venv/lib/python3.10/site-packages/rdflib/namespace/__init__.py:244\u001b[0m, in \u001b[0;36mDefinedNamespaceMeta.__str__\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNamespace(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_NS)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_NS)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, other: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m URIRef:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg_entry = domain_cfg.entries.find_entry_for_file('iso19156-3-examples.csv.ttl')\n",
    "entailed_graph, entail_artifacts = profile_registry.entail(result.graph, cfg_entry.conforms_to, inplace=False)\n",
    "entailed_graph.serialize('iso19156-3-examples.csv-entailed.ttl', format='ttl')\n",
    "print('Entailement done. Artifacts used:')\n",
    "print('-','\\n- '.join(entail_artifacts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb0ac61-9d86-4246-9ed0-b962168a91ca",
   "metadata": {},
   "source": [
    "The above code will find the profiles defined for the `iso19156-3-examples.csv.ttl` file name, and then run the specific entailments for the profiles found in the configuration entry's `dct:conformsTo`. The entailment result (`entailed_graph`) is stored, and a list of all the found entailment artifacts is then written to the console.\n",
    "\n",
    "It is important to note that in our example we could have skipped creating the full `DomainConfiguration`, instantiating a `ProfileRegistry` directly with the profiles SPARQL endpoint instead, but as we will see later, it is much easier to work with the former in an automated CI/CD environment.\n",
    "\n",
    "Validation is done similarly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfba945-93c1-411d-8f90-422de2fcb4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_result = profile_registry.validate(entailed_graph, cfg_entry.conforms_to, log_artifact_errors=True)\n",
    "print('Validation done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc7d991-0344-44e7-92eb-3330a260fd5c",
   "metadata": {},
   "source": [
    "The validation process output logging warnings when profiles and/or artifacts are missing, but if `log_artifact_errors` is `True`, it will take a *best-effort* approach.\n",
    "\n",
    "The `validation_result` will then contain a summary of all the validation errors found, both globally and per profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d6a9a-c0c1-460b-9222-e5d409bf8ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Global:\", validation_result.result)\n",
    "for profile_report in validation_result.reports:\n",
    "    print(f\"{profile_report.profile_uri}: {profile_report.report.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75843c0c-682c-41c6-969a-053229da83e0",
   "metadata": {},
   "source": [
    "We also get full plain text error reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67521800-e8b1-4cfe-acd9-7d84b2d4e1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(validation_result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f5603b-16c4-4717-9d54-e34d4d23996b",
   "metadata": {
    "tags": []
   },
   "source": [
    "As well as an RDF representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8dd741-d216-4134-886a-d1b01a0783cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(validation_result.graph.serialize(format='ttl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a317ea-467a-4cc0-b732-395af595d413",
   "metadata": {},
   "source": [
    "In our example, we can see that the validation for `skos_shared` fails because the SHACL resource employed has errors, but `vocprez_ogc` detects several errors in our data.\n",
    "\n",
    "## Uploading the results\n",
    "\n",
    "Finally, if we want to upload our entailed graphs to a [SPARQL Graph Store Protocol](https://www.w3.org/TR/sparql11-http-rdf-update/)-compatible service, we can use `update_vocabs.load_vocab` to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50511dc7-ccea-404f-9bb0-1a27c087c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # disable upload in this notebook\n",
    "    update_vocabs.load_vocab(result.graph, 'http://example.com/graph-identifier', 'http://example.com/sparql/graph-store', ('username', 'password'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e890bc4-e6e9-495a-93a2-7c97f6f3f3d6",
   "metadata": {},
   "source": [
    "The RDF data will be uploading using the [HTTP PUT method mechanism](https://www.w3.org/TR/sparql11-http-rdf-update/#http-put), which will replace all data in the specified graph URI (`http://example.com/graph-identifier` above) with the contents of the provided graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d9758-951e-4523-9ac9-8316249557ef",
   "metadata": {},
   "source": [
    "# CI/CD environments\n",
    "\n",
    "All of the ogc-na modules can be run directly from the command line, which means that in a CI/CD environment all of them can be run as shell commands.\n",
    "\n",
    "Take the [iso19157-3-sample](https://github.com/avillar/iso19157-3-sample) GitHub repository as an example. It contains several files that should be quite familiar to us by now:\n",
    "\n",
    "* [csv2python.yml](https://github.com/avillar/iso19157-3-sample/blob/master/csv2python.yml) is the uplift definition to turn CSV files into JSON.\n",
    "* [properties-uplift.yml](https://github.com/avillar/iso19157-3-sample/blob/master/properties-uplift.yml) is the uplift definition that converts our JSON rows into JSON-LD/Turtle.\n",
    "* [.ogc/catalog.ttl](https://github.com/avillar/iso19157-3-sample/blob/master/.ogc/catalog.ttl) contains a `DomainConfiguration` like the one we created before, as well as an `UplifConfiguration` to map `*.csv.json` files to `properties-uplift.yml`.\n",
    "\n",
    "Apart from that, we have [.ogc/config.yml](https://github.com/avillar/iso19157-3-sample/blob/master/.ogc/config.yml) with the file download configuration (which we typed in manually above).\n",
    "\n",
    "The pipeline is then run using the [download-and-uplift.yaml](https://github.com/avillar/iso19157-3-sample/blob/master/.github/workflows/download-and-uplift.yaml) GitHub workflow configuration; the important bits in that file are the chain of `python` commands that appear after the environment is set up:\n",
    "\n",
    "```shell\n",
    "# Download file(s)\n",
    "# Inputs:\n",
    "#  - .ogc/config.yml (file download spec)\n",
    "# Outputs:\n",
    "#  - iso19156-3-examples.csv\n",
    "python -m ogc.na.download --spec .ogc/config.yml\n",
    "\n",
    "# Search for CSV files and convert them to JSON\n",
    "# Inputs:\n",
    "#  - iso19156-3-examples.csv (input file)\n",
    "#  - csv2python.yml (uplift definition)\n",
    "# Outputs:\n",
    "#  - iso19156-3-examples.csv.json\n",
    "find . -name '*.csv' | while read CSV_FILE; do python -m ogc.na.ingest_json \\\n",
    "--skip-on-missing-context --json-ld --context csv2python.yml \"${CSV_FILE}\" > \"${CSV_FILE}.json\"\n",
    "done\n",
    "\n",
    "# Do the properties-uplift.yml semantic uplift. The --use-git-status instructs the script to\n",
    "# take its input file names from whatever is modified/added in the current git working directory\n",
    "# Inputs:\n",
    "#  - .ogc/catalog.ttl (domain configurations)\n",
    "#  - iso19156-3-examples.csv.json (input file)\n",
    "#  - properties-uplift.yml (uplift definition found in catalog)\n",
    "# Outputs:\n",
    "#  - iso19156-3-examples.csv.jsonld (uplifted JSON-LD)\n",
    "#  - iso19156-3-examples.csv.ttl (uplifted Turtle)\n",
    "python -m ogc.na.ingest_json --batch --use-git-status --skip-on-missing-context \\\n",
    "--json-ld --ttl --work-dir . --domain-config .ogc/catalog.ttl\n",
    "\n",
    "# Run the entailment, validation and upload in a single step\n",
    "# Inputs:\n",
    "#  - .ogc/catalog.ttl (domain configurations)\n",
    "#  - iso19156-3-examples.csv.ttl (input file)\n",
    "# Outputs:\n",
    "#  - entailed/iso19156-3-examples.csv.jsonld (entailed expanded JSON-LD)\n",
    "#  - entailed/iso19156-3-examples.csv.ttl (entailed Turtle)\n",
    "#  - entailed/iso19156-3-examples.csv.rdf (entailed RDF/XML)\n",
    "#  - entailed/iso19156-3-examples.csv.txt (validation report)\n",
    "python -m ogc.na.update_vocabs -w . .ogc/catalog.ttl --use-git-status \\\n",
    "--base-uri https://raw.githubusercontent.com/${{github.repository}}/${{github.ref_name}} \\\n",
    "--update --graph-store http://defs-dev.opengis.net:8061/fuseki-hosted/data\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
